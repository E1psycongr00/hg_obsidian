{"path":"08. 공부 자료/pdf/book/컴퓨터 과학/Concepts, Techniques, and Models of Computer Programming by Peter Van Roy and Seif Haridi.pdf","text":"Concepts, Techniques, and Models of Computer Programming PETER VAN ROY1 Universit´e catholique de Louvain (at Louvain-la-Neuve) Swedish Institute of Computer Science SEIF HARIDI2 Royal Institute of Technology (KTH) Swedish Institute of Computer Science June 5, 2003 1Email: pvr@info.ucl.ac.be,Web: http://www.info.ucl.ac.be/~pvr 2Email: seif@it.kth.se,Web: http://www.it.kth.se/~seif ii Contents List of Figures xvi List of Tables xxiv Preface xxvii Running the example programs xliii I Introduction 1 1 Introduction to Programming Concepts 3 1.1 A calculator ...... ........... ........... .. 3 1.2 Variables ........ ........... ........... .. 4 1.3 Functions ....... ........... ........... .. 4 1.4 Lists .......... ........... ........... .. 6 1.5 Functions over lists .. ........... ........... .. 9 1.6 Correctness ...... ........... ........... .. 11 1.7 Complexity ...... ........... ........... .. 12 1.8 Lazy evaluation .... ........... ........... .. 13 1.9 Higher-order programming ......... ........... .. 15 1.10 Concurrency ...... ........... ........... .. 16 1.11 Dataﬂow ........ ........... ........... .. 17 1.12 State .......... ........... ........... .. 18 1.13 Objects ........ ........... ........... .. 19 1.14 Classes ......... ........... ........... .. 20 1.15 Nondeterminism and time ......... ........... .. 21 1.16 Atomicity ....... ........... ........... .. 23 1.17 Where do we go from here ......... ........... .. 24 1.18 Exercises ........ ........... ........... .. 24 II General Computation Models 29 2 Declarative Computation Model 31 Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. iv CONTENTSCONTENTS vvi CONTENTSCONTENTS viiviii CONTENTSCONTENTS ixx CONTENTSCONTENTS xixii CONTENTSCONTENTS xiiixiv CONTENTSCONTENTS xvxvi List of Figures 1.1 Taking apart the list [5678] ..... ........... .. 7 1.2 Calculating the ﬁfth row of Pascal’s triangle .......... .. 8 1.3 A simple example of dataﬂow execution .. ........... .. 17 1.4 All possible executions of the ﬁrst nondeterministic example . . . 21 1.5 One possible execution of the second nondeterministic example . . 23 2.1 From characters to statements....... ........... .. 33 2.2 The context-free approach to language syntax ......... .. 35 2.3 Ambiguity in a context-free grammar ... ........... .. 36 2.4 The kernel language approach to semantics ........... .. 39 2.5 Translation approaches to language semantics ......... .. 42 2.6 A single-assignment store with three unbound variables .... .. 44 2.7 Two of the variables are bound to values . ........... .. 44 2.8 A value store: all variables are bound to values ........ .. 45 2.9 A variable identiﬁer referring to an unbound variable ..... .. 46 2.10 A variable identiﬁer referring to a bound variable ....... .. 46 2.11 A variable identiﬁer referring to a value .. ........... .. 47 2.12 A partial value .... ........... ........... .. 47 2.13 A partial value with no unbound variables, i.e., a complete value . 48 2.14 Two variables bound together ....... ........... .. 48 2.15 The store after binding one of the variables ........... .. 49 2.16 The type hierarchy of the declarative model .......... .. 53 2.17 The declarative computation model .... ........... .. 62 2.18 Lifecycle of a memory block ........ ........... .. 76 2.19 Declaring global variables ......... ........... .. 88 2.20 The Browser ...... ........... ........... .. 90 2.21 Exception handling . . ........... ........... .. 92 2.22 Uniﬁcation of cyclic structures ....... ........... .. 102 3.1 A declarative operation inside a general computation ..... .. 114 3.2 Structure of the chapter .......... ........... .. 115 3.3 A classiﬁcation of declarative programming ........... .. 116 3.4 Finding roots using Newton’s method (ﬁrst version)...... .. 121 3.5 Finding roots using Newton’s method (second version) .... .. 123 Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. xviii LIST OF FIGURESLIST OF FIGURES xixxx LIST OF FIGURESLIST OF FIGURES xxixxii LIST OF FIGURESLIST OF FIGURES xxiiixxiv List of Tables 2.1 The declarative kernel language ...... ........... .. 50 2.2 Value expressions in the declarative kernel language ...... .. 51 2.3 Examples of basic operations ........ ........... .. 56 2.4 Expressions for calculating with numbers . ........... .. 82 2.5 The if statement ... ........... ........... .. 83 2.6 The case statement . ........... ........... .. 83 2.7 Function syntax .... ........... ........... .. 85 2.8 Interactive statement syntax........ ........... .. 88 2.9 The declarative kernel language with exceptions ........ .. 94 2.10 Exception syntax ... ........... ........... .. 95 2.11 Equality (uniﬁcation) and equality test (entailment check) . . . . 100 3.1 The descriptive declarative kernel language ........... .. 117 3.2 The parser’s input language (which is a token sequence) .... .. 166 3.3 The parser’s output language (which is a tree) ......... .. 167 3.4 Execution times of kernel instructions ... ........... .. 170 3.5 Memory consumption of kernel instructions ........... .. 176 3.6 The declarative kernel language with secure types ....... .. 206 3.7 Functor syntax .... ........... ........... .. 224 4.1 The data-driven concurrent kernel language .......... .. 240 4.2 The demand-driven concurrent kernel language ......... .. 285 4.3 The declarative concurrent kernel language with exceptions . . . . 332 4.4 Dataﬂow variable as communication channel .......... .. 337 4.5 Classifying synchronization ......... ........... .. 340 5.1 The kernel language with message-passing concurrency .... .. 355 5.2 The nondeterministic concurrent kernel language ........ .. 403 6.1 The kernel language with explicit state . . ........... .. 423 6.2 Cell operations .... ........... ........... .. 423 7.1 Class syntax ...... ........... ........... .. 501 8.1 The kernel language with shared-state concurrency ...... .. 580 Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. xxvi Preface Six blind sages were shown an elephant and met to discuss their ex- perience. “It’s wonderful,” said the ﬁrst, “an elephant is like a rope: slender and ﬂexible.” “No, no, not at all,” said the second, “an ele- phant is like a tree: sturdily planted on the ground.” “Marvelous,” said the third, “an elephant is like a wall.” “Incredible,” said the fourth, “an elephant is a tube ﬁlled with water.” “What a strange piecemeal beast this is,” said the ﬁfth. “Strange indeed,” said the sixth, “but there must be some underlying harmony. Let us investi- gate the matter further.” – Freely adapted from a traditional Indian fable. “A programming language is like a natural, human language in that it favors certain metaphors, images, and ways of thinking.” – Mindstorms: Children, Computers, and Powerful Ideas [141], Sey- mour Papert (1980) One approach to study computer programming is to study programming lan- guages. But there are a tremendously large number of languages, so large that it is impractical to study them all. How can we tackle this immensity? We could pick a small number of languages that are representative of diﬀerent programming paradigms. But this gives little insight into programming as a uniﬁed discipline. This book uses another approach. We focus on programming concepts and the techniques to use them, not on programming languages. The concepts are organized in terms of computation models. A computation model is a formal system that deﬁnes how computations are done. There are many ways to deﬁne computation models. Since this book is intended to be practical, it is important that the computation model should be directly useful to the programmer. We will therefore deﬁne it in terms of concepts that are important to programmers: data types, operations, and a programming language. The term computation model makes precise the imprecise notion of “programming paradigm”. The rest of the book talks about computation models and not programming paradigms. Sometimes we will use the phrase programming model. This refers to what the programmer needs: the programming techniques and design principles made possible by the computation model. Each computation model has its own set of techniques for programming and Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. xxviii PREFACEPREFACE xxixxxx PREFACEPREFACE xxxixxxii PREFACEPREFACE xxxiiixxxiv PREFACEPREFACE xxxvxxxvi PREFACEPREFACE xxxviixxxviii PREFACEPREFACE xxxixxl PREFACEPREFACE xlixlii PREFACE Running the example programs This book gives many example programs and program fragments, All of these can be run on the Mozart Programming System. To make this as easy as possible, please keep the following points in mind: • The Mozart system can be downloaded without charge from the Mozart Consortium Web site http://www.mozart-oz.org. Releases exist for var- ious ﬂavors of Windows and Unix and for Mac OS X. • All examples, except those intended for standalone applications, can be run in Mozart’s interactive development environment. Appendix A gives an introduction to this environment. • New variables in the interactive examples must be declared with the declare statement. The examples of Chapter 1 show how to do it. Forgetting to do this can result in strange errors if older versions of the variables exist. Starting with Chapter 2 and for all succeeding chapters, the declare state- ment is omitted in the text when it is obvious what the new variables are. It should be added to run the examples. • Some chapters use operations that are not part of the standard Mozart re- lease. The source code for these additional operations (along with much other useful material) is given on the book’s Web site. We recommend putting these deﬁnitions into your .ozrc ﬁle, so they will be loaded auto- matically when the system starts up. • There are a few diﬀerences between the ideal implementation of this book and the Mozart system. They are explained on the book’s Web site. Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. Part I Introduction Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. Chapter 1 Introduction to Programming Concepts “There is no royal road to geometry.” – Euclid’s reply to Ptolemy, Euclid (c. 300 BC) “Just follow the yellow brick road.” – The Wonderful Wizard of Oz, L. Frank Baum (1856–1919) Programming is telling a computer how it should do its job. This chapter gives a gentle, hands-on introduction to many of the most important concepts in pro- gramming. We assume you have had some previous exposure to computers. We use the interactive interface of Mozart to introduce programming concepts in a progressive way. We encourage you to try the examples in this chapter on a running Mozart system. This introduction only scratches the surface of the programming concepts we will see in this book. Later chapters give a deep understanding of these concepts and add many other concepts and techniques. 1.1 A calculator Let us start by using the system to do calculations. Start the Mozart system by typing: oz or by double-clicking a Mozart icon. This opens an editor window with two frames. In the top frame, type the following line: {Browse 9999*9999} Use the mouse to select this line. Now go to the Oz menu and select Feed Region. This feeds the selected text to the system. The system then does the calculation Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 4 Introduction to Programming Concepts1.3 Functions 56 Introduction to Programming Concepts1.4 Lists 78 Introduction to Programming Concepts1.5 Functions over lists 910 Introduction to Programming Concepts1.6 Correctness 1112 Introduction to Programming Concepts1.8 Lazy evaluation 1314 Introduction to Programming Concepts1.9 Higher-order programming 1516 Introduction to Programming Concepts1.11 Dataﬂow 1718 Introduction to Programming Concepts1.13 Objects 1920 Introduction to Programming Concepts1.15 Nondeterminism and time 2122 Introduction to Programming Concepts1.16 Atomicity 2324 Introduction to Programming Concepts1.18 Exercises 2526 Introduction to Programming Concepts1.18 Exercises 2728 Introduction to Programming Concepts Part II General Computation Models Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. Chapter 2 Declarative Computation Model “Non sunt multiplicanda entia praeter necessitatem.” “Do not multiply entities beyond necessity.” – Ockham’s Razor, William of Ockham (1285–1349?) Programming encompasses three things: • First, a computation model, which is a formal system that deﬁnes a lan- guage and how sentences of the language (e.g., expressions and statements) are executed by an abstract machine. For this book, we are interested in computation models that are useful and intuitive for programmers. This will become clearer when we deﬁne the ﬁrst one later in this chapter. • Second, a set of programming techniques and design principles used to write programs in the language of the computation model. We will sometimes call this a programming model. A programming model is always built on top of a computation model. • Third, a set of reasoning techniques to let you reason about programs, to increase conﬁdence that they behave correctly and to calculate their eﬃciency. The above deﬁnition of computation model is very general. Not all computation models deﬁned in this way will be useful for programmers. What is a reasonable computation model? Intuitively, we will say that a reasonable model is one that can be used to solve many problems, that has straightforward and practical rea- soning techniques, and that can be implemented eﬃciently. We will have more to say about this question later on. The ﬁrst and simplest computation model we will study is declarative programming. For now, we deﬁne this as evaluating functions over partial data structures. This is sometimes called stateless program- ming, as opposed to stateful programming (also called imperative programming) which is explained in Chapter 6. The declarative model of this chapter is one of the most fundamental com- putation models. It encompasses the core ideas of the two main declarative Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 32 Declarative Computation Model2.1 Deﬁning practical programming languages 3334 Declarative Computation Model2.1 Deﬁning practical programming languages 3536 Declarative Computation Model2.1 Deﬁning practical programming languages 3738 Declarative Computation Model2.1 Deﬁning practical programming languages 3940 Declarative Computation Model2.1 Deﬁning practical programming languages 4142 Declarative Computation Model2.1 Deﬁning practical programming languages 4344 Declarative Computation Model2.2 The single-assignment store 4546 Declarative Computation Model2.2 The single-assignment store 4748 Declarative Computation Model2.2 The single-assignment store 4950 Declarative Computation Model2.3 Kernel language 5152 Declarative Computation Model2.3 Kernel language 5354 Declarative Computation Model2.3 Kernel language 5556 Declarative Computation Model2.4 Kernel language semantics 5758 Declarative Computation Model2.4 Kernel language semantics 5960 Declarative Computation Model2.4 Kernel language semantics 6162 Declarative Computation Model2.4 Kernel language semantics 6364 Declarative Computation Model2.4 Kernel language semantics 6566 Declarative Computation Model2.4 Kernel language semantics 6768 Declarative Computation Model2.4 Kernel language semantics 6970 Declarative Computation Model2.4 Kernel language semantics 7172 Declarative Computation Model2.4 Kernel language semantics 7374 Declarative Computation Model2.4 Kernel language semantics 7576 Declarative Computation Model2.4 Kernel language semantics 7778 Declarative Computation Model2.4 Kernel language semantics 7980 Declarative Computation Model2.5 From kernel language to practical language 8182 Declarative Computation Model2.5 From kernel language to practical language 8384 Declarative Computation Model2.5 From kernel language to practical language 8586 Declarative Computation Model2.5 From kernel language to practical language 8788 Declarative Computation Model2.5 From kernel language to practical language 8990 Declarative Computation Model2.6 Exceptions 9192 Declarative Computation Model2.6 Exceptions 9394 Declarative Computation Model2.6 Exceptions 9596 Declarative Computation Model2.6 Exceptions 9798 Declarative Computation Model2.7 Advanced topics 99100 Declarative Computation Model2.7 Advanced topics 101102 Declarative Computation Model2.7 Advanced topics 103104 Declarative Computation Model2.7 Advanced topics 105106 Declarative Computation Model2.7 Advanced topics 107108 Declarative Computation Model2.8 Exercises 109110 Declarative Computation Model2.8 Exercises 111112 Declarative Computation Model Chapter 3 Declarative Programming Techniques “S’il vous plaˆıt... dessine-moi un arbre!” “If you please – draw me a tree!” – Freely adapted from Le Petit Prince, AntoinedeSaint-Exup´ery (1900–1944) “The nice thing about declarative programming is that you can write a speciﬁcation and run it as a program. The nasty thing about declar- ative programming is that some clear speciﬁcations make incredibly bad programs. The hope of declarative programming is that you can move from a speciﬁcation to a reasonable program without leaving the language.” – The Craft of Prolog, Richard O’Keefe (?–) Consider any computational operation, i.e., a program fragment with inputs and outputs. We say the operation is declarative if, whenever called with the same arguments, it returns the same results independent of any other computation state. Figure 3.1 illustrates the concept. A declarative operation is independent (does not depend on any execution state outside of itself), stateless1 (has no internal execution state that is remembered between calls), and deterministic (always gives the same results when given the same arguments). We will show that all programs written using the computation model of the last chapter are declarative. Why declarative programming is important Declarative programming is important because of two properties: • Declarative programs are compositional. A declarative program con- sists of components that can each be written, tested, and proved correct 114 Declarative Programming Techniques 115116 Declarative Programming Techniques3.1 What is declarativeness? 117118 Declarative Programming Techniques3.1 What is declarativeness? 119120 Declarative Programming Techniques3.2 Iterative computation 121122 Declarative Programming Techniques3.2 Iterative computation 123124 Declarative Programming Techniques3.2 Iterative computation 125126 Declarative Programming Techniques3.3 Recursive computation 127128 Declarative Programming Techniques3.3 Recursive computation 129130 Declarative Programming Techniques3.4 Programming with recursion 131132 Declarative Programming Techniques3.4 Programming with recursion 133134 Declarative Programming Techniques3.4 Programming with recursion 135136 Declarative Programming Techniques3.4 Programming with recursion 137138 Declarative Programming Techniques3.4 Programming with recursion 139140 Declarative Programming Techniques3.4 Programming with recursion 141142 Declarative Programming Techniques3.4 Programming with recursion 143144 Declarative Programming Techniques3.4 Programming with recursion 145146 Declarative Programming Techniques3.4 Programming with recursion 147148 Declarative Programming Techniques3.4 Programming with recursion 149150 Declarative Programming Techniques3.4 Programming with recursion 151152 Declarative Programming Techniques3.4 Programming with recursion 153154 Declarative Programming Techniques3.4 Programming with recursion 155156 Declarative Programming Techniques3.4 Programming with recursion 157158 Declarative Programming Techniques3.4 Programming with recursion 159160 Declarative Programming Techniques3.4 Programming with recursion 161162 Declarative Programming Techniques3.4 Programming with recursion 163164 Declarative Programming Techniques3.4 Programming with recursion 165166 Declarative Programming Techniques3.4 Programming with recursion 167168 Declarative Programming Techniques3.5 Time and space eﬃciency 169170 Declarative Programming Techniques3.5 Time and space eﬃciency 171172 Declarative Programming Techniques3.5 Time and space eﬃciency 173174 Declarative Programming Techniques3.5 Time and space eﬃciency 175176 Declarative Programming Techniques3.5 Time and space eﬃciency 177178 Declarative Programming Techniques3.5 Time and space eﬃciency 179180 Declarative Programming Techniques3.6 Higher-order programming 181182 Declarative Programming Techniques3.6 Higher-order programming 183184 Declarative Programming Techniques3.6 Higher-order programming 185186 Declarative Programming Techniques3.6 Higher-order programming 187188 Declarative Programming Techniques3.6 Higher-order programming 189190 Declarative Programming Techniques3.6 Higher-order programming 191192 Declarative Programming Techniques3.6 Higher-order programming 193194 Declarative Programming Techniques3.6 Higher-order programming 195196 Declarative Programming Techniques3.7 Abstract data types 197198 Declarative Programming Techniques3.7 Abstract data types 199200 Declarative Programming Techniques3.7 Abstract data types 201202 Declarative Programming Techniques3.7 Abstract data types 203204 Declarative Programming Techniques3.7 Abstract data types 205206 Declarative Programming Techniques3.7 Abstract data types 207208 Declarative Programming Techniques3.7 Abstract data types 209210 Declarative Programming Techniques3.7 Abstract data types 211212 Declarative Programming Techniques3.8 Nondeclarative needs 213214 Declarative Programming Techniques3.8 Nondeclarative needs 215216 Declarative Programming Techniques3.8 Nondeclarative needs 217218 Declarative Programming Techniques3.8 Nondeclarative needs 219220 Declarative Programming Techniques3.9 Program design in the small 221222 Declarative Programming Techniques3.9 Program design in the small 223224 Declarative Programming Techniques3.9 Program design in the small 225226 Declarative Programming Techniques3.9 Program design in the small 227228 Declarative Programming Techniques3.9 Program design in the small 229230 Declarative Programming Techniques3.9 Program design in the small 231232 Declarative Programming Techniques3.10 Exercises 233234 Declarative Programming Techniques3.10 Exercises 235236 Declarative Programming Techniques Chapter 4 Declarative Concurrency “Twenty years ago, parallel skiing was thought to be a skill attain- able only after many years of training and practice. Today, it is routinely achieved during the course of a single skiing season. [...] All the goals of the parents are achieved by the children: [...] But the movements they make in order to produce these results are quite diﬀerent.” – Mindstorms: Children, Computers, and Powerful Ideas [141], Sey- mour Papert (1980) The declarative model of Chapter 2 lets us write many programs and use powerful reasoning techniques on them. But, as Section 4.7 explains, there exist useful programs that cannot be written easily or eﬃciently in it. For example, some programs are best written as a set of activities that execute independently. Such programs are called concurrent. Concurrency is essential for programs that interact with their environment, e.g., for agents, GUI programming, OS interac- tion, and so forth. Concurrency also lets a program be organized into parts that execute independently and interact only when needed, i.e., client/server and pro- ducer/consumer programs. This is an important software engineering property. Concurrency can be simple This chapter extends the declarative model of Chapter 2 with concurrency while still being declarative. That is, all the programming and reasoning techniques for declarative programming still apply. This is a remarkable property that deserves to be more widely known. We will explore it throughout this chapter. The intuition underlying it is quite simple. It is based on the fact that a dataﬂow variable can be bound to only one value. This gives the following two consequences: • What stays the same: The result of a program is the same whether or not it is concurrent. Putting any part of the program in a thread does not change the result. Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 238 Declarative Concurrency4.1 The data-driven concurrent model 239240 Declarative Concurrency4.1 The data-driven concurrent model 241242 Declarative Concurrency4.1 The data-driven concurrent model 243244 Declarative Concurrency4.1 The data-driven concurrent model 245246 Declarative Concurrency4.1 The data-driven concurrent model 247248 Declarative Concurrency4.1 The data-driven concurrent model 249250 Declarative Concurrency4.2 Basic thread programming techniques 251252 Declarative Concurrency4.2 Basic thread programming techniques 253254 Declarative Concurrency4.2 Basic thread programming techniques 255256 Declarative Concurrency4.2 Basic thread programming techniques 257258 Declarative Concurrency4.2 Basic thread programming techniques 259260 Declarative Concurrency4.3 Streams 261262 Declarative Concurrency4.3 Streams 263264 Declarative Concurrency4.3 Streams 265266 Declarative Concurrency4.3 Streams 267268 Declarative Concurrency4.3 Streams 269270 Declarative Concurrency4.3 Streams 271272 Declarative Concurrency4.3 Streams 273274 Declarative Concurrency4.3 Streams 275276 Declarative Concurrency4.4 Using the declarative concurrent model directly 277278 Declarative Concurrency4.4 Using the declarative concurrent model directly 279280 Declarative Concurrency4.4 Using the declarative concurrent model directly 281282 Declarative Concurrency4.5 Lazy execution 283284 Declarative Concurrency4.5 Lazy execution 285286 Declarative Concurrency4.5 Lazy execution 287288 Declarative Concurrency4.5 Lazy execution 289290 Declarative Concurrency4.5 Lazy execution 291292 Declarative Concurrency4.5 Lazy execution 293294 Declarative Concurrency4.5 Lazy execution 295296 Declarative Concurrency4.5 Lazy execution 297298 Declarative Concurrency4.5 Lazy execution 299300 Declarative Concurrency4.5 Lazy execution 301302 Declarative Concurrency4.5 Lazy execution 303304 Declarative Concurrency4.5 Lazy execution 305306 Declarative Concurrency4.5 Lazy execution 307308 Declarative Concurrency4.6 Soft real-time programming 309310 Declarative Concurrency4.6 Soft real-time programming 311312 Declarative Concurrency4.6 Soft real-time programming 313314 Declarative Concurrency4.7 Limitations and extensions of declarative programming 315316 Declarative Concurrency4.7 Limitations and extensions of declarative programming 317318 Declarative Concurrency4.7 Limitations and extensions of declarative programming 319320 Declarative Concurrency4.7 Limitations and extensions of declarative programming 321322 Declarative Concurrency4.7 Limitations and extensions of declarative programming 323324 Declarative Concurrency4.7 Limitations and extensions of declarative programming 325326 Declarative Concurrency4.8 The Haskell language 327328 Declarative Concurrency4.8 The Haskell language 329330 Declarative Concurrency4.8 The Haskell language 331332 Declarative Concurrency4.9 Advanced topics 333334 Declarative Concurrency4.9 Advanced topics 335336 Declarative Concurrency4.9 Advanced topics 337338 Declarative Concurrency4.9 Advanced topics 339340 Declarative Concurrency4.9 Advanced topics 341342 Declarative Concurrency4.10 Historical notes 343344 Declarative Concurrency4.11 Exercises 345346 Declarative Concurrency4.11 Exercises 347348 Declarative Concurrency4.11 Exercises 349350 Declarative Concurrency4.11 Exercises 351352 Declarative Concurrency Chapter 5 Message-Passing Concurrency “Only then did Atreyu notice that the monster was not a single, solid body, but was made up of innumerable small steel-blue insects which buzzed like angry hornets. It was their compact swarm that kept taking diﬀerent shapes.” – The Neverending Story, Michael Ende (1929–1995) In the last chapter we saw how to program with stream objects, which is both declarative and concurrent. But it has the limitation that it cannot handle observable nondeterminism. For example, we wrote a digital logic simulator in which each stream object knows exactly which object will send it the next mes- sage. We cannot program a client/server where the server does not know which client will send it the next message. We can remove this limitation by extending the model with an asynchronous communication channel. Then any client can send messages to the channel and the server can read them from the channel. We use a simple kind of channel called a port that has an associated stream. Sending a message to the port causes the message to appear on the port’s stream. The extended model is called the message-passing concurrent model. Since this model is nondeterministic, it is no longer declarative. A client/server program can give diﬀerent results on diﬀerent executions because the order of client sends is not determined. A useful programming style for this model is to associate a port to each stream object. The object reads all its messages from the port, and sends messages to other stream objects through their ports. This style keeps most of the advantages of the declarative model. Each stream object is deﬁned by a recursive procedure that is declarative. Another programming style is to use the model directly, programming with ports, dataﬂow variables, threads, and procedures. This style can be useful for building concurrency abstractions, but it is not recommended for large programs because it is harder to reason about. Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 354 Message-Passing Concurrency5.1 The message-passing concurrent model 355356 Message-Passing Concurrency5.2 Port objects 357358 Message-Passing Concurrency5.2 Port objects 359360 Message-Passing Concurrency5.3 Simple message protocols 361362 Message-Passing Concurrency5.3 Simple message protocols 363364 Message-Passing Concurrency5.3 Simple message protocols 365366 Message-Passing Concurrency5.3 Simple message protocols 367368 Message-Passing Concurrency5.3 Simple message protocols 369370 Message-Passing Concurrency5.4 Program design for concurrency 371372 Message-Passing Concurrency5.4 Program design for concurrency 373374 Message-Passing Concurrency5.4 Program design for concurrency 375376 Message-Passing Concurrency5.4 Program design for concurrency 377378 Message-Passing Concurrency5.4 Program design for concurrency 379380 Message-Passing Concurrency5.4 Program design for concurrency 381382 Message-Passing Concurrency5.4 Program design for concurrency 383384 Message-Passing Concurrency5.5 Using the message-passing concurrent model directly 385386 Message-Passing Concurrency5.5 Using the message-passing concurrent model directly 387388 Message-Passing Concurrency5.5 Using the message-passing concurrent model directly 389390 Message-Passing Concurrency5.5 Using the message-passing concurrent model directly 391392 Message-Passing Concurrency5.5 Using the message-passing concurrent model directly 393394 Message-Passing Concurrency5.6 The Erlang language 395396 Message-Passing Concurrency5.6 The Erlang language 397398 Message-Passing Concurrency5.6 The Erlang language 399400 Message-Passing Concurrency5.6 The Erlang language 401402 Message-Passing Concurrency5.7 Advanced topics 403404 Message-Passing Concurrency5.7 Advanced topics 405406 Message-Passing Concurrency5.8 Exercises 407408 Message-Passing Concurrency5.8 Exercises 409410 Message-Passing Concurrency5.8 Exercises 411412 Message-Passing Concurrency Chapter 6 Explicit State “L’´etat c’est moi.” “I am the state.” – Louis XIV (1638–1715) “If declarative programming is like a crystal, immutable and prac- tically eternal, then stateful programming is organic: it grows and evolves as we watch.” – Inspired by On Growth and Form, D’Arcy Wentworth Thompson (1860–1948) At ﬁrst glance, explicit state is just a minor extension to declarative program- ming: in addition to depending on its arguments, the component’s result also depends on an internal parameter, which is called its “state”. This parameter gives the component a long-term memory, a “sense of history” if you will. 1 With- out state, a component has only short-term memory, one that exists during a particular invocation of the component. State adds a potentially inﬁnite branch to a ﬁnitely running program. By this we mean the following. A component that runs for a ﬁnite time can only have gathered a ﬁnite amount of information. If the component has state, then to this ﬁnite information can be added the information stored by the state. This “history” can be indeﬁnitely long, since the component can have a memory that reaches far into the past. Oliver Sacks has described the case of people with brain damage who only have a short-term memory [161]. They live in a continuous “present” with no memory beyond a few seconds into the past. The mechanism to “ﬁx” short-term memories into the brain’s long-term storage is broken. Strange it must be to live in this way. Perhaps these people use the external world as a kind of long-term memory? This analogy gives some idea of how important state can be for people. We will see that state is just as important for programming. 414 Explicit State 415416 Explicit State6.1 What is state? 417418 Explicit State6.2 State and system building 419420 Explicit State6.3 The declarative model with explicit state 421422 Explicit State6.3 The declarative model with explicit state 423424 Explicit State6.3 The declarative model with explicit state 425426 Explicit State6.4 Abstract data types 427428 Explicit State6.4 Abstract data types 429430 Explicit State6.4 Abstract data types 431432 Explicit State6.4 Abstract data types 433434 Explicit State6.4 Abstract data types 435436 Explicit State6.4 Abstract data types 437438 Explicit State6.5 Stateful collections 439440 Explicit State6.5 Stateful collections 441442 Explicit State6.5 Stateful collections 443444 Explicit State6.6 Reasoning with state 445446 Explicit State6.6 Reasoning with state 447448 Explicit State6.6 Reasoning with state 449450 Explicit State6.6 Reasoning with state 451452 Explicit State6.7 Program design in the large 453454 Explicit State6.7 Program design in the large 455456 Explicit State6.7 Program design in the large 457458 Explicit State6.7 Program design in the large 459460 Explicit State6.7 Program design in the large 461462 Explicit State6.7 Program design in the large 463464 Explicit State6.7 Program design in the large 465466 Explicit State6.8 Case studies 467468 Explicit State6.8 Case studies 469470 Explicit State6.8 Case studies 471472 Explicit State6.8 Case studies 473474 Explicit State6.8 Case studies 475476 Explicit State6.8 Case studies 477478 Explicit State6.8 Case studies 479480 Explicit State6.8 Case studies 481482 Explicit State6.8 Case studies 483484 Explicit State6.9 Advanced topics 485486 Explicit State6.10 Exercises 487488 Explicit State6.10 Exercises 489490 Explicit State6.10 Exercises 491492 Explicit State Chapter 7 Object-Oriented Programming “The fruit is too well known to need any description of its external characteristics.” – From entry “Apple”, Encyclopaedia Britannica (11th edition) This chapter introduces a particularly useful way of structuring stateful pro- grams called object-oriented programming. It introduces one new concept over the last chapter, namely inheritance, which allows to deﬁne ADTs in incremen- tal fashion. However, the computation model is the same stateful model as in the previous chapter. We can loosely deﬁne object-oriented programming as programming with encapsulation, explicit state, and inheritance. It is often sup- ported by a linguistic abstraction, the concept of class, but it does not have to be. Object-oriented programs can be written in almost any language. From a historical viewpoint, the introduction of object-oriented programming made two major contributions to the discipline of programming. First, it made clear that encapsulation is essential. Programs should be organized as collec- tions of ADTs. This was ﬁrst clearly stated in the classic article on “information hiding” [142], reprinted in [144]. Each module, component, or object has a “se- cret” known only to itself. Second, it showed the importance of building ADTs incrementally, using inheritance. This avoids duplicated code. Object-oriented programming is one of the most successful and pervasive ar- eas in informatics. From its timid beginnings in the 1960’s it has invaded every area of informatics, both in scientiﬁc research and technology development. The ﬁrst object-oriented language was Simula 67, developed in 1967 as a descendant of Algol 60 [130, 137, 152]. Simula 67 was much ahead of its time and had little immediate inﬂuence. Much more inﬂuential in making object-oriented program- ming popular was Smalltalk-80, released in 1980 as the result of research done in the 1970’s [60]. The currently most popular programming languages, Java and C++, are object-oriented [186, 184]. The most popular “language-independent” design aids, the Uniﬁed Modeling Language (UML) and Design Patterns, both implicitly assume that the underlying language is object-oriented [58, 159]. With Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 494 Object-Oriented Programming7.1 Motivations 495496 Object-Oriented Programming7.1 Motivations 497498 Object-Oriented Programming7.2 Classes as complete ADTs 499500 Object-Oriented Programming7.2 Classes as complete ADTs 501502 Object-Oriented Programming7.2 Classes as complete ADTs 503504 Object-Oriented Programming7.2 Classes as complete ADTs 505506 Object-Oriented Programming7.3 Classes as incremental ADTs 507508 Object-Oriented Programming7.3 Classes as incremental ADTs 509510 Object-Oriented Programming7.3 Classes as incremental ADTs 511512 Object-Oriented Programming7.3 Classes as incremental ADTs 513514 Object-Oriented Programming7.3 Classes as incremental ADTs 515516 Object-Oriented Programming7.3 Classes as incremental ADTs 517518 Object-Oriented Programming7.3 Classes as incremental ADTs 519520 Object-Oriented Programming7.3 Classes as incremental ADTs 521522 Object-Oriented Programming7.3 Classes as incremental ADTs 523524 Object-Oriented Programming7.4 Programming with inheritance 525526 Object-Oriented Programming7.4 Programming with inheritance 527528 Object-Oriented Programming7.4 Programming with inheritance 529530 Object-Oriented Programming7.4 Programming with inheritance 531532 Object-Oriented Programming7.4 Programming with inheritance 533534 Object-Oriented Programming7.4 Programming with inheritance 535536 Object-Oriented Programming7.4 Programming with inheritance 537538 Object-Oriented Programming7.4 Programming with inheritance 539540 Object-Oriented Programming7.4 Programming with inheritance 541542 Object-Oriented Programming7.5 Relation to other computation models 543544 Object-Oriented Programming7.5 Relation to other computation models 545546 Object-Oriented Programming7.5 Relation to other computation models 547548 Object-Oriented Programming7.5 Relation to other computation models 549550 Object-Oriented Programming7.5 Relation to other computation models 551552 Object-Oriented Programming7.6 Implementing the object system 553554 Object-Oriented Programming7.6 Implementing the object system 555556 Object-Oriented Programming7.7 The Java language (sequential part) 557558 Object-Oriented Programming7.7 The Java language (sequential part) 559560 Object-Oriented Programming7.7 The Java language (sequential part) 561562 Object-Oriented Programming7.8 Active objects 563564 Object-Oriented Programming7.8 Active objects 565566 Object-Oriented Programming7.8 Active objects 567568 Object-Oriented Programming7.8 Active objects 569570 Object-Oriented Programming7.8 Active objects 571572 Object-Oriented Programming7.8 Active objects 573574 Object-Oriented Programming7.9 Exercises 575576 Object-Oriented Programming Chapter 8 Shared-State Concurrency The shared-state concurrent model is a simple extension to the declarative con- current model that adds explicit state in the form of cells, which are a kind of mu- table variable. This model is equivalent in expressiveness to the message-passing concurrent model of Chapter 5, because cells can be eﬃciently implemented with ports and vice versa. In practice, however, the shared-state model is harder to program than the message-passing model. Let us see what the problem is and how wecan solveit. The inherent diﬃculty of the model Let us ﬁrst see exactly why the shared-state model is so diﬃcult. Execution consists of multiple threads, all executing independently and all accessing shared cells. At some level, a thread’s execution can be seen as a sequence of atomic instructions. For a cell, these are @ (access), := (assignment), and Exchange. Because of the interleaving semantics, all execution happens as if there was one global order of operations. All operations of all threads are therefore “interleaved” to make this order. There are many possible interleavings; their number is limited only by data dependencies (calculations needing results of others). Any particular execution realizes an interleaving. Because thread scheduling is nondeterministic, there is no way to know which interleaving will be chosen. But just how many interleavings are possible? Let us consider a simple case: two threads, each doing k cell operations. Thread T1 does the operations a1, a2, ..., ak and thread T2 does b1, b2, ..., bk. How many possible executions are there, interleaving all these operations? It is easy to see that the number is \u0012 2k k \u0013 . Any interleaved execution consists of 2k operations, of which each thread takes k. Consider these operations as integers from 1 to 2k, put in a set. Then T1 takes k integers from this set and T2 gets the others. This number is exponential in k. 1 For three or more threads, the number of interleavings is even bigger (see Exercises). 578 Shared-State Concurrency 579580 Shared-State Concurrency8.1 The shared-state concurrent model 581582 Shared-State Concurrency8.2 Programming with concurrency 583584 Shared-State Concurrency8.2 Programming with concurrency 585586 Shared-State Concurrency8.2 Programming with concurrency 587588 Shared-State Concurrency8.2 Programming with concurrency 589590 Shared-State Concurrency8.3 Locks 591592 Shared-State Concurrency8.3 Locks 593594 Shared-State Concurrency8.3 Locks 595596 Shared-State Concurrency8.3 Locks 597598 Shared-State Concurrency8.3 Locks 599600 Shared-State Concurrency8.4 Monitors 601602 Shared-State Concurrency8.4 Monitors 603604 Shared-State Concurrency8.4 Monitors 605606 Shared-State Concurrency8.4 Monitors 607608 Shared-State Concurrency8.5 Transactions 609610 Shared-State Concurrency8.5 Transactions 611612 Shared-State Concurrency8.5 Transactions 613614 Shared-State Concurrency8.5 Transactions 615616 Shared-State Concurrency8.5 Transactions 617618 Shared-State Concurrency8.5 Transactions 619620 Shared-State Concurrency8.5 Transactions 621622 Shared-State Concurrency8.5 Transactions 623624 Shared-State Concurrency8.6 The Java language (concurrent part) 625626 Shared-State Concurrency8.7 Exercises 627628 Shared-State Concurrency8.7 Exercises 629630 Shared-State Concurrency8.7 Exercises 631632 Shared-State Concurrency Chapter 9 Relational Programming “Toward the end of the thirteenth century, Ram´on Llull (Raimundo Lulio or Raymond Lully) invented the thinking machine. [...] The circumstances and objectives of this machine no longer interest us, but its guiding principle–the methodical application of chance to the resolution of a problem–still does.” –Ram´on Llull’s Thinking Machine, Jorge Luis Borges (1899–1986) “In retrospect it can now be said that the ars magna Lulli was the ﬁrst seed of what is now called “symbolic logic,” but it took a long time until the seed brought fruit, this particular fruit.” – Postscript to the “Universal Library”, Willy Ley (1957) A procedure in the declarative model uses its input arguments to calculate the values of its output arguments. This is a functional calculation, in the math- ematical sense: the outputs are functions of the inputs. For a given set of input argument values, there is only one set of output argument values. We can gen- eralize this to become relational. A relational procedure is more ﬂexible in two ways than a functional procedure. First, there can be any number of results to a call, either zero (no results), one, or more. Second, which arguments are inputs and which are outputs can be diﬀerent for each call. This ﬂexibility makes relational programming well-suited for databases and parsers, in particular for diﬃcult cases such as deductive databases and parsing ambiguous grammars. It can also be used to enumerate solutions to complex combinatoric problems. We have used it to automatically generate diagnostics for a RISC microprocessor, the VLSI-BAM [84, 193]. The diagnostics enumerate all possible instruction sequences that use register forwarding. Relational pro- gramming has also been used in artiﬁcial intelligence applications such as David Warren’s venerable WARPLAN planner [39]. From the programmer’s point of view, relational programming extends declar- ative programming with a new kind of statement called “choice”. Conceptually, the choice statement nondeterministically picks one among a set of alternatives. Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 634 Relational Programming9.1 The relational computation model 635636 Relational Programming9.1 The relational computation model 637638 Relational Programming9.2 Further examples 639640 Relational Programming9.2 Further examples 641642 Relational Programming9.2 Further examples 643644 Relational Programming9.3 Relation to logic programming 645646 Relational Programming9.3 Relation to logic programming 647648 Relational Programming9.3 Relation to logic programming 649650 Relational Programming9.3 Relation to logic programming 651652 Relational Programming9.3 Relation to logic programming 653654 Relational Programming9.4 Natural language parsing 655656 Relational Programming9.4 Natural language parsing 657658 Relational Programming9.4 Natural language parsing 659660 Relational Programming9.4 Natural language parsing 661662 Relational Programming9.5 A grammar interpreter 663664 Relational Programming9.5 A grammar interpreter 665666 Relational Programming9.6 Databases 667668 Relational Programming9.6 Databases 669670 Relational Programming9.6 Databases 671672 Relational Programming9.7 The Prolog language 673674 Relational Programming9.7 The Prolog language 675676 Relational Programming9.7 The Prolog language 677678 Relational Programming9.7 The Prolog language 679680 Relational Programming9.7 The Prolog language 681682 Relational Programming9.7 The Prolog language 683684 Relational Programming9.8 Exercises 685686 Relational Programming Part III Specialized Computation Models Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. Chapter 10 Graphical User Interface Programming “Nowadays the growth of a graphic image can be divided into two sharply deﬁned phases. The process begins with the search for a visual form that will interpret as clearly as possible one’s train of thought. [...] After this, to my great relief, there dawns the second phase, that is the making of the graphic print; for now the spirit can take its rest while the work is taken over by the hands.” – The Graphic Work of M.C. Escher, M.C. Escher (1898–1972) This chapter shows a particularly simple and powerful way to do graphical user interface (GUI) programming. We combine the declarative model together with the shared-state concurrent model in an approach that takes advantage of the good properties of each model. To introduce the approach, let us ﬁrst summarize the existing approaches: • Purely procedural. The user interface is constructed by a sequence of graph- ics commands. These commands can be purely imperative, as in tcl/tk, object-oriented, as in the Java AWT (Abstract Window Toolkit) package or its extension, the Swing components, or even functional, as in Haskell fud- gets. The object-oriented or functional style is preferable to an imperative style because it is easier to structure the graphics commands. • Purely declarative. The user interface is constructed by choosing from a set of predeﬁned possibilities. This is an example of descriptive declarativeness, as explained in Section 3.1. A well-known example is HTML (HyperText Markup Language), the formatting language used for Web pages. • Using an interface builder. The user interface is constructed manually by the developer, using a direct manipulation interface. A well-known example is Microsoft Visual Studio. Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 690 Graphical User Interface Programming10.1 Basic concepts 691692 Graphical User Interface Programming10.2 Using the declarative/procedural approach 693694 Graphical User Interface Programming10.2 Using the declarative/procedural approach 695696 Graphical User Interface Programming10.2 Using the declarative/procedural approach 697698 Graphical User Interface Programming10.3 Case studies 699700 Graphical User Interface Programming10.3 Case studies 701702 Graphical User Interface Programming10.3 Case studies 703704 Graphical User Interface Programming10.3 Case studies 705706 Graphical User Interface Programming10.3 Case studies 707708 Graphical User Interface Programming10.3 Case studies 709710 Graphical User Interface Programming10.3 Case studies 711712 Graphical User Interface Programming Chapter 11 Distributed Programming A distributed system is a set of computers that are linked together by a network. Distributed systems are ubiquitous in modern society. The canonical example of such a system, the Internet, has been growing exponentially ever since its inception in the late 1970’s. The number of host computers that are part of it has been doubling each year since 1980. The question of how to program a distributed system is therefore of major importance. This chapter shows one approach to programming a distributed system. For the rest of the chapter, we assume that each computer has an operating system that supports the concept of process and provides network communication.Pro- gramming a distributed system then means to write a program for each process such that all processes taken together implement the desired application. For the operating system, a process is a unit of concurrency. This means that if we ab- stract away from the fact that the application is spread over diﬀerent processes, this is just a case of concurrent programming. Ideally, distributed programming would be just a kind of concurrent programming, and the techniques we have seen earlier in the book would still apply. Distributed programming is complicated Unfortunately, things are not so simple. Distributed programming is more com- plicated than concurrent programming for the following reasons: • Each process has its own address space. Data cannot be transferred from one process to another without some translation. • The network has limited performance. Typically, the basic network opera- tions are many orders of magnitude slower than the basic operations inside one process. At the time of publication of this book, network transfer time is measured in milliseconds, whereas computational operations are done in nanoseconds or less. This enormous disparity is not projected to change for the foreseeable future. Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 714 Distributed Programming 715716 Distributed Programming11.1 Taxonomy of distributed systems 717718 Distributed Programming11.2 The distribution model 719720 Distributed Programming11.3 Distribution of declarative data 721722 Distributed Programming11.3 Distribution of declarative data 723724 Distributed Programming11.3 Distribution of declarative data 725726 Distributed Programming11.4 Distribution of state 727728 Distributed Programming11.5 Network awareness 729730 Distributed Programming11.6 Common distributed programming patterns 731732 Distributed Programming11.6 Common distributed programming patterns 733734 Distributed Programming11.6 Common distributed programming patterns 735736 Distributed Programming11.6 Common distributed programming patterns 737738 Distributed Programming11.7 Distribution protocols 739740 Distributed Programming11.7 Distribution protocols 741742 Distributed Programming11.7 Distribution protocols 743744 Distributed Programming11.8 Partial failure 745746 Distributed Programming11.8 Partial failure 747748 Distributed Programming11.9 Security 749750 Distributed Programming11.10 Building applications 751752 Distributed Programming11.11 Exercises 753754 Distributed Programming Chapter 12 Constraint Programming “Plans within plans within plans within plans.” – Dune, Frank Herbert (1920–1986) Constraint programming consists of a set of techniques for solving constraint satisfaction problems.1 A constraint satisfaction problem,or CSP, consists of a set of constraints on a set of variables. A constraint, in this setting, is simply a logical relation, such as “X is less than Y” or “X is a multiple of 3”. The ﬁrst problem is to ﬁnd whether there exists a solution, without necessarily constructing it. The second problem is to ﬁnd one or more solutions. A CSP can always be solved with brute force search. All possible values of all variables are enumerated and each is checked to see whether it is a solution. Except in very small problems, the number of candidates is usually too large to enumerate them all. Constraint programming has developed “smart” ways to solve CSPs which greatly reduce the amount of search needed. This is suﬃcient to solve many practical problems. For many problems, though, search cannot be entirely eliminated. Solving CSPs is related to deep questions of intractability. Problems that are known to be intractable will always need some search. The hope of constraint programming is that, for the problems that interest us, the search component can be reduced to an acceptable level. Constraint programming is qualitatively diﬀerent from the other programming paradigms that we have seen, such as declarative, object-oriented, and concurrent programming. Compared to these paradigms, constraint programming is much closer to the ideal of declarative programming: to say what we want without saying how to achieve it. Structure of the chapter This chapter introduces a quite general approach for tackling CSPs called propagate- and-search or propagate-and-distribute. The chapter is structured as follows: 756 Constraint Programming12.1 Propagate and search 757758 Constraint Programming12.1 Propagate and search 759760 Constraint Programming12.2 Programming techniques 761762 Constraint Programming12.2 Programming techniques 763764 Constraint Programming12.3 The constraint-based computation model 765766 Constraint Programming12.4 Computation spaces 767768 Constraint Programming12.4 Computation spaces 769770 Constraint Programming12.4 Computation spaces 771772 Constraint Programming12.4 Computation spaces 773774 Constraint Programming12.4 Computation spaces 775776 Constraint Programming12.5 Implementing the relational computation model 777778 Constraint Programming12.6 Exercises 779780 Constraint Programming Part IV Semantics Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. Chapter 13 Language Semantics “This is the secret meaning of the runes; I hid here magic-runes, undisturbed by evil witchcraft. In misery shall he die by means of magic art who destroys this monument.” – Runic inscription, Bj¨orketorp Stone For all the computation models of the previous chapters, we gave a formal se- mantics in terms of a simple abstract machine. For the declarative model, this abstract machine contains two main parts: a single-assignment store and a seman- tic stack. For concurrency, we extended the machine to have multiple semantic stacks. For lazy execution we added a trigger store. For explicit state we added a mutable store. For read-only views we added a read-only store. This chapter brings all these pieces together. It deﬁnes an operational seman- tics for all the computation models of the previous chapters.1 We use a diﬀerent formalism than the abstract machine of the previous chapters. The formalism of this chapter is more compact and easier to reason with than the abstract machine deﬁnitions. It has three principal changes with respect to the abstract machine of Chapter 2: • It uses a concise notation based on reduction rules. The reduction rules follow the abstract syntax, i.e., there are one or more rules for each syntactic construct. This approach is called Structural Operational Semantics, or SOS for short. It was pioneered by Gordon Plotkin [208]. • It uses substitutions instead of environments. We saw that statements, in order to be reducible, must deﬁne bindings for their free identiﬁers. In the abstract machine, these bindings are given by the environment in the semantic statement. In this chapter, the free identiﬁers are directly substi- tuted by references into the store. We have the invariant that in a reducible statement, all free identiﬁers have been replaced by store references. 784 Language Semantics13.1 The shared-state concurrent model 785786 Language Semantics13.1 The shared-state concurrent model 787788 Language Semantics13.1 The shared-state concurrent model 789790 Language Semantics13.1 The shared-state concurrent model 791792 Language Semantics13.1 The shared-state concurrent model 793794 Language Semantics13.1 The shared-state concurrent model 795796 Language Semantics13.1 The shared-state concurrent model 797798 Language Semantics13.1 The shared-state concurrent model 799800 Language Semantics13.1 The shared-state concurrent model 801802 Language Semantics13.1 The shared-state concurrent model 803804 Language Semantics13.1 The shared-state concurrent model 805806 Language Semantics13.2 Declarative concurrency 807808 Language Semantics13.4 Semantics of common abstractions 809810 Language Semantics13.6 Exercises 811812 Language Semantics13.6 Exercises 813814 Language Semantics Part V Appendices Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. Appendix A Mozart System Development Environment “Beware the ides of March.” –Soothsayer toJuliusCaesar, William Shakespeare (1564–1616) The Mozart system used in this book has a complete IDE (Interactive De- velopment Environment). To get you started, we give a brief overview of this environment here. We refer you to the system documentation for additional in- formation. A.1 Interactive interface The Mozart system has an interactive interface that is based on the Emacs text editor. The interfactive interface is sometimes called the OPI, which stands for Oz Programming Interface. The OPI is split into several buﬀers: scratch pad, Oz emulator, Oz compiler, and one buﬀer for each open ﬁle. This interface gives access to several tools: incremental compiler (which can compile any legal pro- gram fragment), Browser (visualize the single-assignment store), Panel (resource usage), Compiler Panel (compiler settings and environment), Distribution Panel (distribution subsystem including message traﬃc), and the Explorer (interactive graphical resolution of constraint problems). These tools can also be manipulated from within programs, e.g., the Compiler module allows to compile strings from within programs. A.1.1 Interface commands You can access all the important OPI commands through the menus at the top of the window. Most of these commands have keyboard equivalents. We give the most important ones: Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 818 Mozart System Development EnvironmentA.2 Batch interface 819820 Mozart System Development Environment Appendix B Basic Data Types “Wie het kleine niet eert is het grote niet weert.” “He who does not honor small things is not worthy of great things.” – Traditional Dutch proverb. This appendix explains the most common basic data types in Oz together with some common operations. The types explained are numbers (including integers and ﬂoating point numbers), characters (which are represented as small integers), literals (constants of two types, either atoms or names), records, tuples, chunks (records with a limited set of operations), lists, strings (which are represented as lists of characters), and virtual strings (strings represented as tuples). For each data type discussed in this appendix, there is a corresponding Base module in the Mozart system that deﬁnes all operations on the data type. This appendix gives some but not all of these operations. See the Mozart system documentation for complete information [49]. B.1 Numbers (integers, ﬂoats, and characters) The following code fragment introduces four variables I, H, F and C. It binds I to an integer, H to an integer in hexadecimal notation, F to a ﬂoat, and C to the character t in this order. It then displays I, H, F,and C: declare IHFC in I=˜5 H = 0xDadBeddedABadBadBabe F = 5.5 C=&t {Browse I} {Browse H} {Browse F} {Browse C} Note that ˜ (tilde) is the unary minus symbol. This displays the following: ˜5 1033532870595452951444158 5.5 Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 822 Basic Data TypesB.1 Numbers (integers, ﬂoats, and characters) 823824 Basic Data TypesB.2 Literals (atoms and names) 825826 Basic Data TypesB.3 Records and tuples 827828 Basic Data TypesB.4 Chunks (limited records) 829830 Basic Data TypesB.5 Lists 831832 Basic Data TypesB.7 Virtual strings 833834 Basic Data Types Appendix C Language Syntax “The devil is in the details.” – Traditional proverb. “God is in the details.” – Traditional proverb. “I don’t know what is in those details, but it must be something important!” – Irreverent proverb. This appendix deﬁnes the syntax of the complete language used in this book, including all syntactic conveniences. The language is a subset of the Oz language as implemented by the Mozart system. The appendix is divided into six sections: • Section C.1 deﬁnes the syntax of interactive statements, i.e., statements that can be fed into the interactive interface. • Section C.2 deﬁnes the syntax of statements and expressions. • Section C.3 deﬁnes the syntax of the nonterminals needed to deﬁne state- ments and expressions. • Section C.4 lists the operators of the language with their precedence and associativity. • Section C.5 lists the keywords of the language. • Section C.6 deﬁnes the lexical syntax of the language, i.e., how a character sequence is transformed into a sequence of tokens. To be precise, this appendix deﬁnes a context-free syntax for a superset of the language. This keeps the syntax simple and easy to read. The disadvantage of a context-free syntax is that it does not capture all syntactic conditions for legal programs. For example, take the statement local X in ⟨statement⟩ end.The Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 836 Language SyntaxC.2 Statements and expressions 837838 Language SyntaxC.4 Operators 839840 Language SyntaxC.5 Keywords 841842 Language SyntaxC.6 Lexical syntax 843844 Language Syntax Appendix D General Computation Model “The removal of much of the accidental complexity of programming means that the intrinsic complexity of the application is what’s left.” – Security Engineering, Ross J. Anderson (2001) “If you want people to do something the right way, you must make the right way the easy way.” – Traditional saying. This appendix brings together all the general concepts introduced in the book.1 The resulting computation model is the shared-state concurrent model of Chap- ter 8. For convenience we call it the general computation model. While this model is quite general, it is certainly not the ﬁnal word in computation models. It is just a snapshot that captures our current understanding of programming. Future research will certainly change or extend it. The book mentions dynamic scoping and transaction support as two areas which require more support from the model. The general computation model was designed in a layered fashion, by starting from a simple base model and successively adding new concepts. Each time we noted a limitation in the expressiveness of a computation model, we had the opportunity to add a new concept. There was always a choice: either to keep the model as is and make programs more complicated, or to add a concept and keep programs simple. The decision to add the concept or not was based on our judgement of how complicated the model and its programs would be, when considered together. “Complexity” in this sense covers both the expressiveness and ease of reasoning of the combination. There is a strong element of creativity in this approach. Each concept brings something novel that was not there before. We therefore call it the creative extension principle. Not all useful concepts end up in the general model. Some concepts were added only to be superseded by later concepts. For example, this is the case for nondeterministic choice (Section 5.7.1), which is superseded 846 General Computation ModelD.2 Kernel language 847848 General Computation ModelD.3 Concepts 849850 General Computation ModelD.5 Other concepts 851852 General Computation Model Bibliography [1] Harold Abelson, Gerald Jay Sussman, and Julie Sussman. Structure and Interpretation of Computer Programs. The MIT Press, Cambridge, Mass, 1985. [2] Harold Abelson, Gerald Jay Sussman, and Julie Sussman. Structure and Interpretation of Computer Programs, Second Edition. The MIT Press, Cambridge, Mass, 1996. [3] Ili`es Alouini and Peter Van Roy. Le protocole r´eparti du langage Distributed Oz (The distributed protocol of the Distributed Oz language). In Colloque Francophone d’Ing´enierie de Protocoles (CFIP 99), pages 283–298, April 1999. [4] Edward G. Amoroso. Fundamentals of Computer Security Technology. Prentice Hall, 1994. [5] Ross J. Anderson. Security Engineering: A Guide to Building Dependable Distributed Systems. John Wiley & Sons, 2001. [6] Gregory R. Andrews. Concurrent Programming: Principles and Practice. Addison-Wesley, 1991. [7] Joe Armstrong. Higher-order processes in Erlang, January 1997. Unpub- lished talk. [8] Joe Armstrong. Concurrency oriented programming in Erlang, November 2002. Invited talk, Lightweight Languages Workshop 2002. [9] Joe Armstrong, Mike Williams, Claes Wikstr¨om, and Robert Virding. Con- current Programming in Erlang. Prentice-Hall, Englewood Cliﬀs, N.J., 1996. [10] Ken Arnold and James Gosling. The Java Programming Language, Second Edition. Addison-Wesley, 1998. [11] Arvind and R. E. Thomas. I-Structures: An eﬃcient data type for func- tional languages. Technical Report 210, MIT, Laboratory for Computer Science, 1980. Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 854 BIBLIOGRAPHYBIBLIOGRAPHY 855856 BIBLIOGRAPHYBIBLIOGRAPHY 857858 BIBLIOGRAPHYBIBLIOGRAPHY 859860 BIBLIOGRAPHYBIBLIOGRAPHY 861862 BIBLIOGRAPHYBIBLIOGRAPHY 863864 BIBLIOGRAPHYBIBLIOGRAPHY 865866 BIBLIOGRAPHYBIBLIOGRAPHY 867868 BIBLIOGRAPHY Index ! (escaped variable marker), 506, 515 ! (cut) operation (in Prolog), 675, 679, 682 $ (nesting marker), 54, 85, 363, 373 * (multiplication) operation, 56, 823 + (addition) operation, 56, 823 - (subtraction) operation, 56, 823 . (ﬁeld selector) operation, 56, 828 .:= (dictionary/array assignment) state- ment, 439, 440, 841 .:= (dictionary/array exchange) ex- pression, 841 / (ﬂoating division) operation, 56, 824 := (state assignment) statement, 499, 502 := (state exchange) expression, 502 = (binding) operation, 45, 47, 48, 101 == (equality) comparison, 57 =< (less or equal) comparison, 57 ? (output argument), 59, 843 @ (state access) operation, 499, 502 # (tupling) constructor, 143, 827, 833 & (inline character) operator, 822 < (strictly less) comparison, 57, 832 <= (optional method argument) opera- tor, 505 > (strictly greater) comparison, 57 >= (greater or equal) comparison, 57 \\ (backslash), 823 \\= (inequality) comparison, 57 ˜ (minus sign), 822 | (list pairing) constructor, 54 Abelson, Harold, xxxiii, 43 absolute error, 122 abstract machine, 43 relation to semantic rules, 789 substitution-based, 128–129 abstract syntax tree, 164, 165 abstraction, xxxii active object, 563 class, 498 collection, 438 collector, 192, 326, 434, 488 connector, 326 control, 125 database, 667 encapsulated search, 637 hierarchy in object-oriented program- ming, 552 lifecycle, 42 Linda (tuple space), 594 linguistic, 40–41, 126 case (pattern matching), 793 class, 554 conc (concurrent composition), 283 delegation, 520 for loop, 190, 451 fun (function), 85 functor (software component), 227 gate (logic gate), 276 local vs. global translation, 846 monitor, 601 parameter passing, 438 protected scope (Java), 574 while loop, 451 list comprehension, 307 lock, 590, 606 loop, 184 mailbox, 398 monitor, 600 pipe of stream objects, 567 procedural, 180 protector, 326 queue, 149, 303 replicator, 326 software component, 223 Copyright c⃝ 2001-3 by P. Van Roy and S. Haridi. All rights reserved. 870 INDEXINDEX 871872 INDEXINDEX 873874 INDEXINDEX 875876 INDEXINDEX 877878 INDEXINDEX 879880 INDEXINDEX 881882 INDEXINDEX 883884 INDEXINDEX 885886 INDEXINDEX 887888 INDEXINDEX 889890 INDEXINDEX 891892 INDEXINDEX 893894 INDEXINDEX 895896 INDEX","libVersion":"0.3.2","langs":""}