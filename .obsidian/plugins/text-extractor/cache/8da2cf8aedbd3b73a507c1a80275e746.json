{"path":"attachments/screenshot/Pasted image 20240302203517.png","text":"‘We elaborate the principled instructions for LLM prompting, provide further mo- tivation, and detail several specific designing principles in Section 3. In Section 4 we show experimentally that the proposed principles can produce higher quality, more concise, factual and less complicated or intricate responses than standard prompts for LLMs. Specifically, with the manually-designed ATLAS benchmark, which includes multiple questions for cach principle] the Specializéd prompts we introduced have ent hanced both the quality and accuracy of the LLM responses by an average of 57.7% and 36.4%, respectively, when applied to GPT-4. Furthermore, the improvements are more pronounced with the increase in model size, for example, the performance gains when moving from LLaMA-2-7B to GPT-4 exceed 20%.","libVersion":"0.3.2","langs":"eng+kor"}